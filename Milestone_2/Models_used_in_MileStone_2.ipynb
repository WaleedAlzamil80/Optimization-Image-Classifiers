{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "6S4-sbDHot98"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.losses import *\n",
        "from tensorflow.keras.optimizers import *\n",
        "\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.initializers import random_uniform\n",
        "from tensorflow.python.framework.ops import EagerTensor"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def leNet(input_shape, num_classes):\n",
        "    model=tf.keras.models.Sequential()\n",
        "\n",
        "    model.add(tf.keras.layers.experimental.preprocessing.Resizing(28, 28, interpolation=\"bilinear\", input_shape=input_shape))\n",
        "    \n",
        "    model.add (tf.keras.layers.Conv2D(filters=6, kernel_size=(5,5), strides=(1,1), activation='tanh' ) )\n",
        "    model.add(tf.keras.layers.AveragePooling2D(pool_size=(2,2), strides=(2,2)))\n",
        "    \n",
        "    model.add (tf.keras.layers.Conv2D(filters=16, kernel_size=(5,5), strides=(1,1), activation='tanh' )) \n",
        "    model.add(tf.keras.layers.AveragePooling2D(pool_size=(2,2), strides=(2,2)))\n",
        "    \n",
        "    model.add(tf.keras.layers.Flatten())\n",
        "    model.add(tf.keras.layers.Dense(120,activation='tanh'))\n",
        "    model.add(tf.keras.layers.Dense(84,activation='tanh'))\n",
        "    model.add(tf.keras.layers.Dense(num_classes,activation='softmax'))\n",
        "\n",
        "    model.compile(optimizer = \"adam\", loss = \"categorical_crossentropy\", metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "PdZjcdDGpNn7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def VGG16(input_shape, num_classes):\n",
        "    model=tf.keras.models.Sequential()\n",
        "\n",
        "    model.add(tf.keras.layers.experimental.preprocessing.Resizing(224, 224, interpolation=\"bilinear\", input_shape=input_shape))\n",
        "\n",
        "    model.add (tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), activation='relu',padding=\"same\" ) )\n",
        "    model.add (tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), activation='relu',padding=\"same\" ) )\n",
        "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
        "\n",
        "    model.add (tf.keras.layers.Conv2D(filters=128, kernel_size=(3,3), strides=(1,1), activation='relu',padding=\"same\" ) )\n",
        "    model.add (tf.keras.layers.Conv2D(filters=128, kernel_size=(3,3), strides=(1,1), activation='relu',padding=\"same\" ) )\n",
        "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
        "\n",
        "    model.add (tf.keras.layers.Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), activation='relu',padding=\"same\" ) )\n",
        "    model.add (tf.keras.layers.Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), activation='relu',padding=\"same\" ) )\n",
        "    model.add (tf.keras.layers.Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), activation='relu',padding=\"same\" ) )\n",
        "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
        "\n",
        "    model.add (tf.keras.layers.Conv2D(filters=512, kernel_size=(3,3), strides=(1,1), activation='relu',padding=\"same\" ) )\n",
        "    model.add (tf.keras.layers.Conv2D(filters=512, kernel_size=(3,3), strides=(1,1), activation='relu',padding=\"same\" ) )\n",
        "    model.add (tf.keras.layers.Conv2D(filters=512, kernel_size=(3,3), strides=(1,1), activation='relu',padding=\"same\" ) )\n",
        "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
        "\n",
        "    model.add (tf.keras.layers.Conv2D(filters=512, kernel_size=(3,3), strides=(1,1), activation='relu',padding=\"same\" ) )\n",
        "    model.add (tf.keras.layers.Conv2D(filters=512, kernel_size=(3,3), strides=(1,1), activation='relu',padding=\"same\" ) )\n",
        "    model.add (tf.keras.layers.Conv2D(filters=512, kernel_size=(3,3), strides=(1,1), activation='relu',padding=\"same\" ) )\n",
        "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
        "\n",
        "    model.add(tf.keras.layers.Flatten())\n",
        "\n",
        "    model.add(tf.keras.layers.Dense(4096,activation='relu'))\n",
        "    model.add(tf.keras.layers.Dense(4096,activation='relu'))\n",
        "\n",
        "    model.add(tf.keras.layers.Dense(num_classes,activation='softmax'))\n",
        "\n",
        "    model.compile(optimizer = \"adam\", loss = \"categorical_crossentropy\", metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "3u8nTT-spmhX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Alex():\n",
        "  model=tf.keras.models.Sequential()\n",
        "\n",
        "  model.add(layers.experimental.preprocessing.Resizing(227, 227, interpolation=\"bilinear\", input_shape=(32, 32, 3)))\n",
        "\n",
        "  model.add(layers.Conv2D(filters=96, kernel_size=(11,11), strides=(4,4),activation='relu',input_shape=(227, 227,3),padding='same'))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.MaxPooling2D(pool_size=(3,3),strides=(2,2)))\n",
        "\n",
        "  model.add(layers.Conv2D(filters=256, kernel_size=(5,5), padding=\"same\",activation=\"relu\",strides=(1,1)))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.MaxPooling2D(pool_size=(3,3),strides=(2,2)))\n",
        "\n",
        "  model.add(layers.Conv2D(kernel_size=(3,3),filters=384,activation='relu',padding='same',strides=(1,1)))\n",
        "  model.add(layers.BatchNormalization())\n",
        "\n",
        "  model.add(layers.Conv2D(filters=384,kernel_size=(3,3),padding='same',activation='relu',strides=(1,1)))\n",
        "  model.add(layers.BatchNormalization())\n",
        "\n",
        "  model.add(layers.Conv2D(filters=256, kernel_size=(3,3),padding='same',activation='relu',strides=(1,1)))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.MaxPooling2D(pool_size=(3,3),strides=(2,2)))\n",
        "\n",
        "  model.add(layers.Flatten())\n",
        "  model.add(layers.Dense(4096,activation='relu'))\n",
        "  model.add(layers.Dropout(0.5))\n",
        "\n",
        "  model.add(layers.Dense(4096,activation='relu'))\n",
        "  model.add(layers.Dropout(0.5))\n",
        "\n",
        "  model.add(layers.Dense(100, activation='softmax'))\n",
        "\n",
        "  model.compile(optimizer = \"adam\", loss = \"categorical_crossentropy\", metrics=['accuracy'])\n",
        "  \n",
        "  return model"
      ],
      "metadata": {
        "id": "ajbj7GeZp8ZP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def identity_block(X, f, filters, training=True, initializer=random_uniform):\n",
        "    \"\"\"\n",
        "    Implementation of the identity block as defined in Figure 4\n",
        "    \n",
        "    Arguments:\n",
        "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
        "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
        "    training -- True: Behave in training mode\n",
        "                False: Behave in inference mode\n",
        "    initializer -- to set up the initial weights of a layer. Equals to random uniform initializer\n",
        "    \n",
        "    Returns:\n",
        "    X -- output of the identity block, tensor of shape (m, n_H, n_W, n_C)\n",
        "    \"\"\"\n",
        "    \n",
        "    # Retrieve Filters\n",
        "    F1, F2, F3 = filters\n",
        "    \n",
        "    # Save the input value. You'll need this later to add back to the main path. \n",
        "    X_shortcut = X\n",
        "    \n",
        "    # First component of main path\n",
        "    X = Conv2D(filters = F1, kernel_size = 1, strides = (1,1), padding = 'valid', kernel_initializer = initializer(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3)(X, training = training) # Default axis\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    ## Second component of main path (≈3 lines)\n",
        "    ## Set the padding = 'same'\n",
        "    X = Conv2D(filters = F2, kernel_size = f, strides = (1,1), padding = 'same', kernel_initializer = initializer(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3)(X, training = training)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    ## Third component of main path (≈2 lines)\n",
        "    ## Set the padding = 'valid'\n",
        "    X = Conv2D(filters = F3, kernel_size = 1, strides = (1,1), padding = 'valid', kernel_initializer = initializer(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3)(X, training = training) \n",
        "    \n",
        "    ## Final step: Add shortcut value to main path, and pass it through a RELU activation (≈2 lines)\n",
        "    X = Add()([X_shortcut, X])\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    return X\n",
        "\n",
        "\n",
        "def identity_block(X, f, filters, training=True, initializer=random_uniform):\n",
        "    \"\"\"\n",
        "    Implementation of the identity block as defined in Figure 4\n",
        "    \n",
        "    Arguments:\n",
        "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
        "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
        "    training -- True: Behave in training mode\n",
        "                False: Behave in inference mode\n",
        "    initializer -- to set up the initial weights of a layer. Equals to random uniform initializer\n",
        "    \n",
        "    Returns:\n",
        "    X -- output of the identity block, tensor of shape (m, n_H, n_W, n_C)\n",
        "    \"\"\"\n",
        "    \n",
        "    # Retrieve Filters\n",
        "    F1, F2, F3 = filters\n",
        "    \n",
        "    # Save the input value. You'll need this later to add back to the main path. \n",
        "    X_shortcut = X\n",
        "    \n",
        "    # First component of main path\n",
        "    X = Conv2D(filters = F1, kernel_size = 1, strides = (1,1), padding = 'valid', kernel_initializer = initializer(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3)(X, training = training) # Default axis\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    ## Second component of main path (≈3 lines)\n",
        "    ## Set the padding = 'same'\n",
        "    X = Conv2D(filters = F2, kernel_size = f, strides = (1,1), padding = 'same', kernel_initializer = initializer(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3)(X, training = training)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    ## Third component of main path (≈2 lines)\n",
        "    ## Set the padding = 'valid'\n",
        "    X = Conv2D(filters = F3, kernel_size = 1, strides = (1,1), padding = 'valid', kernel_initializer = initializer(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3)(X, training = training) \n",
        "    \n",
        "    ## Final step: Add shortcut value to main path, and pass it through a RELU activation (≈2 lines)\n",
        "    X = Add()([X_shortcut, X])\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    return X\n",
        "\n",
        "def ResNet50(input_shape = (32, 32, 3), classes = 100):\n",
        "    \"\"\"\n",
        "    Stage-wise implementation of the architecture of the popular ResNet50:\n",
        "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
        "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> FLATTEN -> DENSE \n",
        "\n",
        "    Arguments:\n",
        "    input_shape -- shape of the images of the dataset\n",
        "    classes -- integer, number of classes\n",
        "\n",
        "    Returns:\n",
        "    model -- a Model() instance in Keras\n",
        "    \"\"\"\n",
        "    \n",
        "    # Define the input as a tensor with shape input_shape\n",
        "    X_input = Input(input_shape)\n",
        "\n",
        "    \n",
        "    # Zero-Padding\n",
        "    X = ZeroPadding2D((3, 3))(X_input)\n",
        "    \n",
        "    # Stage 1\n",
        "    X = Conv2D(64, (7, 7), strides = (2, 2), kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3)(X)\n",
        "    X = Activation('relu')(X)\n",
        "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
        "\n",
        "    # Stage 2\n",
        "    X = convolutional_block(X, f = 3, filters = [64, 64, 256], s = 1)\n",
        "    X = identity_block(X, 3, [64, 64, 256])\n",
        "    X = identity_block(X, 3, [64, 64, 256])\n",
        "    X = Dropout(0.2)(X) # New\n",
        "\n",
        "    ## Stage 3 (≈4 lines)\n",
        "    X = convolutional_block(X, f = 3, filters = [128, 128, 512], s = 2)\n",
        "    X = identity_block(X, 3, [128, 128, 512])\n",
        "    X = identity_block(X, 3, [128, 128, 512])\n",
        "    X = identity_block(X, 3, [128, 128, 512])\n",
        "    \n",
        "    ## Stage 4 (≈6 lines)\n",
        "    X = convolutional_block(X, f = 3, filters = [256, 256, 1024], s = 2)\n",
        "    X = identity_block(X, 3, [256, 256, 1024])\n",
        "    X = identity_block(X, 3, [256, 256, 1024]) \n",
        "    X = identity_block(X, 3, [256, 256, 1024]) \n",
        "    X = identity_block(X, 3, [256, 256, 1024]) \n",
        "    X = identity_block(X, 3, [256, 256, 1024]) \n",
        "    X = Dropout(0.2)(X) # New\n",
        "\n",
        "    ## Stage 5 (≈3 lines)\n",
        "    X = convolutional_block(X, f = 3, filters = [512, 512, 2048], s = 2)\n",
        "    X = identity_block(X, 3, [512, 512, 2048])\n",
        "    X = identity_block(X, 3, [512, 512, 2048]) \n",
        "\n",
        "    ## AVGPOOL (≈1 line). Use \"X = AveragePooling2D(...)(X)\"\n",
        "    X =  AveragePooling2D((2,2))(X)\n",
        "\n",
        "    # output layer\n",
        "    X = Flatten()(X)\n",
        "    X = Dense(classes, activation='softmax', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "\n",
        "    # Create model\n",
        "    model = Model(inputs = X_input, outputs = X)\n",
        "\n",
        "    # Compile model\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "dET5LDXPrERl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def MobileNet_V2(input_shape = (32, 32, 3), classes = 100):\n",
        "\n",
        "  # Create an instance of pre-trained mobile net model\n",
        "  base_model = tf.keras.applications.MobileNetV2(input_shape=input_shape,\n",
        "                                                include_top=False,\n",
        "                                                weights='imagenet')\n",
        "\n",
        "  # Add dense, dropout and batch normalization layers on the pre-trained model\n",
        "  x = base_model.output\n",
        "  x = GlobalAveragePooling2D()(x)\n",
        "  x = Dense(256, activation='relu')(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Dropout(0.5)(x)\n",
        "  predictions = Dense(classes, activation='softmax')(x)\n",
        "\n",
        "  # Create final output layer with SoftMax activation function\n",
        "  model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "  # Change batch size, activation function and optimize as rmsprop\n",
        "  model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "9Qe4cA1-sKDR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def DenseNet121(input_shape = (32, 32, 3), classes = 100):\n",
        "\n",
        "  # Create an instance of a pre-trained model - DenseNet121\n",
        "  base_model = tf.keras.applications.DenseNet121(input_shape=input_shape, include_top=False, weights='imagenet')\n",
        "\n",
        "  # Freeze the top layers of the pre-trained model\n",
        "  for layer in base_model.layers:\n",
        "      layer.trainable = False\n",
        "\n",
        "  # Add a dense layer and dropout layer\n",
        "  x = base_model.output\n",
        "  x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "  x = Dense(256, activation='relu')(x)\n",
        "  x = Dropout(0.2)(x)\n",
        "  predictions = Dense(classes, activation='softmax')(x)\n",
        "\n",
        "  # Create the final model\n",
        "  model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "  # Compile the model\n",
        "  model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "fDgN6DBisJ4R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Feature Extraction is performed by ResNet50 pretrained on imagenet weights. \n",
        "Input size is 224 x 224.\n",
        "'''\n",
        "def feature_extractor(inputs):\n",
        "\n",
        "  feature_extractor = tf.keras.applications.resnet.ResNet50(input_shape=(224, 224, 3),\n",
        "                                               include_top=False,\n",
        "                                               weights='imagenet')(inputs)\n",
        "  return feature_extractor\n",
        "\n",
        "\n",
        "'''\n",
        "Defines final dense layers and subsequent softmax layer for classification.\n",
        "'''\n",
        "def classifier(inputs):\n",
        "    x = tf.keras.layers.GlobalAveragePooling2D()(inputs)\n",
        "    x = tf.keras.layers.Flatten()(x)\n",
        "    x = tf.keras.layers.Dense(1024, activation=\"relu\")(x)\n",
        "    x = tf.keras.layers.Dense(512, activation=\"relu\")(x)\n",
        "    x = tf.keras.layers.Dense(10, activation=\"softmax\", name=\"classification\")(x)\n",
        "    return x\n",
        "\n",
        "'''\n",
        "Since input image size is (32 x 32), first upsample the image by factor of (7x7) to transform it to (224 x 224)\n",
        "Connect the feature extraction and \"classifier\" layers to build the model.\n",
        "'''\n",
        "def final_model(inputs):\n",
        "\n",
        "    resize = tf.keras.layers.UpSampling2D(size=(7,7))(inputs)\n",
        "\n",
        "    resnet_feature_extractor = feature_extractor(resize)\n",
        "    classification_output = classifier(resnet_feature_extractor)\n",
        "\n",
        "    return classification_output\n",
        "\n",
        "'''\n",
        "Define the model and compile it. \n",
        "Use Stochastic Gradient Descent as the optimizer.\n",
        "Use Sparse Categorical CrossEntropy as the loss function.\n",
        "'''\n",
        "def define_compile_model():\n",
        "  inputs = tf.keras.layers.Input(shape=(32,32,3))\n",
        "  \n",
        "  classification_output = final_model(inputs) \n",
        "  model = tf.keras.Model(inputs=inputs, outputs = classification_output)\n",
        " \n",
        "  model.compile(optimizer='Adam', \n",
        "                loss='categorical_crossentropy',\n",
        "                metrics = ['accuracy'])\n",
        "  \n",
        "  return model\n",
        "\n",
        "\n",
        "# model = define_compile_model()\n",
        "\n",
        "# model.summary()\n",
        "\n",
        "def preprocess_image_input(input_images):\n",
        "  input_images = input_images.astype('float32')\n",
        "  output_ims = tf.keras.applications.resnet50.preprocess_input(input_images)\n",
        "  return output_ims"
      ],
      "metadata": {
        "id": "bsKIyDd_txCh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}